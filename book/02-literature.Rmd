# Literature

\section*{Analytic Learning Theory}
This section covers basic definitions and concepts of statistical learning theory.  we approach this from a functional analytic viewpoint.
Supervised learning in its most abstract setting requires finding a function $f(x)$ given instances ${ (x_i ,f(x_i))}$. Typically ${x_i}$ is an independent and identially distribute (iid) sample from some unknown distribution.  A loss function is a random variable
\[ L : Ran(f) \times Ran(f) \rightarrow \dblr^+\]
 defining the cost of misclassification.  The risk associated with a candidate function $f'$ is defined to be the expectation of the loss over the sample space $\Omega$,
\begin{equation*} R(f')=\int L( f(\omega), f'(\omega)) d\omega\end{equation*}.
Statistical learning theory is concerned with assessing the approximations to $f$ given by minimizing the empirical loss associated with a sample ${x_i ,f(x_i)}$.

The notion of a loss function goes back to the roots of modern probability theory and economics.  The St. Petersburg paradox is an example of a random variable $S : \dbln \rightarrow \dblr^=$ with infinite expectation limited utility. Let $W(k)$ be the winnings after k plays of from a game with outcome $S$ that pays $2^{i-1}$ with probability $p_i=1/2^i$. The expected payout is given by
\begin{equation*}
\lim_{k\To\infty} W(k)/k =E(S)=\sum\limits_{i=1}^{\infty} p_i 2^{i-1}= \infty
\end{equation*} The implication for a decision theory based only on expected value is that a rational player would pay an infinite amount of money to play this game. Bernoulli introduced the notion of expected utility which takes into account the fact that a payout of $2^i$ may not have twice the utility of a payout of $2^{i+1}$ when $i$ gets large.  The utility $U$ is a random variable on the sample space representing preferences of an agent.  Loss represents the aversion of an agent to the outcomes of the sample space, $L(\omega)+U(\omega) = \alpha \fall \omega \in \Omega$ where $\alpha$ is constant.  Expected loss $R(f')$ is the risk associated with choosing the approximation $f'$. Restricting the class of functions to consider when minimizing the risk for a candidate approximation to $f$ is a key aspect of classifier design.

(BBCREVISIT GP  RKHS )Gaussian processes provide a class of models and learning algorithms for real world problems that have a long history and are well characterized. Learning algorithms are cast as minimization problems $$min_\mathcal(H) R() $$ in a Hilbert space $$ \mathcal{H}$$ with a dot product that encapsulates a model and sample data.  Bayesian methods are often employed for estimation and inference with Gaussian processes. They allow an intuitive approach to incorporating prior knowledge in classification problems and the ability to obtain confidence intervals for predictions.  Many common regression and classification algorithms can be cast as minimization problems in a Reproducing Kernel Hilbert Space (RKHS).


